{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758d9de9-3c48-48cf-af26-fd2cbcc97ae7",
   "metadata": {},
   "source": [
    "# Data Engineer Interview Questions\n",
    "\n",
    "Please read the questions and place your answer in the code cell below. \n",
    "\n",
    "Feel free to use any resources available to you during the interview. This includes searching on the internet and asking us for any clarification on these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b57d-556b-4f26-93f6-66e75ff8e14f",
   "metadata": {},
   "source": [
    "Q-1. Write a SQL query to fetch records that are present in one table but not in another table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef72886-1c51-4035-ad14-82d993f6e22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "672a8c8b-29f6-4d1f-8739-e7790cecbfe7",
   "metadata": {},
   "source": [
    "Q-2. Write SQL command(s) to delete certain records from a hive table (for example, can use filter where line_of_business='Medicare') ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c715a-4d1a-4d05-af69-c8fb8c683b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03df07fc-5eca-4c74-8c89-c826818ec9cc",
   "metadata": {},
   "source": [
    "Q-3. What is wrong with this SQL statement ?  select count(1), name from employee;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc93ab-15b0-44aa-8fbd-473061030823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa224d52-cfb2-45d0-a9a0-4c4401c8fdc2",
   "metadata": {},
   "source": [
    "Q-4. What tool(s) have you used to automate ETL pipelines in production ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb5b96-6f6e-4996-ae0b-1ae47492683d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e951c854-a8b0-472e-a60a-8d79dd6f3c5e",
   "metadata": {},
   "source": [
    "Q-5. Write Hadoop hdfs commands to look at list of HDFS files for table A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef8b54-b718-4c50-ac78-cfc7e6cb6a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f34e91-00e5-40d5-8bc0-7d0cf4d2ca27",
   "metadata": {},
   "source": [
    "Q-6. What Hive/SQL command will you use to serach and replace a pattern in a string ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fc6e8-7f45-4d4f-8b5b-e84062038d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4794580f-4feb-4663-afc3-fa3a211a24a5",
   "metadata": {},
   "source": [
    "Q-7. What is node and cluster in Hadoop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0039ab-553a-49dc-9034-ee3aaf692271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74ba6a3b-fd79-4247-a7fe-6f8c042aa1a2",
   "metadata": {},
   "source": [
    "Q-8. How would you export the data in a hive table in Hadoop to a CSV file ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1b4d1-91fa-4514-a70d-afb19316b201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f10ccf68-fe75-45ff-9638-e2683e830a18",
   "metadata": {},
   "source": [
    "Q-9. What are the ways to improve performance of ETL pipelines in Hadoop, so they complete in a reasonable amount of time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e24b5-5d24-47e8-8fd9-29f3b1dac424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98dbafc-8392-48d4-9538-6e6b7546b489",
   "metadata": {},
   "source": [
    "Q-10. If there is a huge table with billions of records, what is the most efficient way to create the table in Hadoop  for better performance ? (while running queries against this table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138730a-566c-4110-a8ba-88980891d51e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
